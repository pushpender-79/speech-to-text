🎙️ Speech-to-Text App (MERN Stack + Deepgram)

This project converts audio to text using the Deepgram Speech-to-Text API.
It’s built with the MERN stack — MongoDB, Express.js, React.js, and Node.js — and styled with Tailwind CSS.

🚀 Tech Stack
Layer	Technology
🎨 Frontend	React + Vite + Tailwind CSS
⚙️ Backend	Node.js + Express.js
🗄️ Database	MongoDB (Mongoose)
🧠 Speech-to-Text API	Deepgram
🧰 Tools	Multer, dotenv, nodemon, Git & GitHub
🧠 Project Overview

The app allows users to:

🎤 Record or upload audio

🔊 Convert it to text using Deepgram Speech-to-Text API

💾 Store audio file details & transcriptions in MongoDB

🧾 Retrieve and display saved transcriptions (coming next)

🗓️ Progress Overview
Day	Focus	Status
Day 1	Project setup (Vite + Tailwind + GitHub)	✅ Done
Day 2	Backend setup with Express & Multer	✅ Done
Day 3	MongoDB integration with Mongoose	✅ Done
Day 4	Deepgram Speech-to-Text API integration	✅ Done
Day 5	React UI for Upload & Recording	🔜 Next
⚙️ Installation & Setup
1️⃣ Clone the Repository
git clone https://github.com/pushpender-79/speech-to-text
cd speech-to-text

2️⃣ Frontend Setup
cd client
npm install
npm run dev


App runs at ➡️ http://localhost:5173

3️⃣ Backend Setup
cd ../server
npm install


Dependencies include:

express
cors
multer
dotenv
mongoose
@deepgram/sdk
nodemon (dev dependency)

4️⃣ Environment Variables

Create a .env file inside the server folder:

PORT=5000
MONGO_URI=your_mongodb_connection_string
DEEPGRAM_API_KEY=your_deepgram_api_key

5️⃣ Start the Backend Server
npm run dev


Server runs at ➡️ http://localhost:5000

🧩 API Endpoints
✅ Test Route

GET http://localhost:5000/
Response:

"Backend is running 🚀"

🎧 Upload & Transcribe Audio

POST http://localhost:5000/upload

Form Data:

Key	Type	Description
audio	File	Upload an audio file (.wav, .mp3, etc.)

Response Example:

{
  "message": "File uploaded and transcribed successfully",
  "file": {
    "originalname": "harvard.wav",
    "filename": "1760551563788.wav",
    "mimetype": "audio/wav",
    "path": "uploads/1760551563788.wav"
  },
  "transcription": "This is a sample transcription text generated by Deepgram."
}

🗄️ MongoDB Schema (Day 3)
import mongoose from "mongoose";

const audioSchema = new mongoose.Schema({
  filename: { type: String, required: true },
  transcription: { type: String, default: "" },
  uploadedAt: { type: Date, default: Date.now },
});

export default mongoose.model("Audio", audioSchema);


Collection Name: audios

Field	Description
filename	File name stored on the server
transcription	Generated text after Deepgram transcription
uploadedAt	Timestamp of upload
🧠 Deepgram API Integration (Day 4)

Using @deepgram/sdk v4:

import { createClient } from "@deepgram/sdk";
const deepgram = createClient(process.env.DEEPGRAM_API_KEY);

const { result } = await deepgram.listen.prerecorded.transcribeFile(audioBuffer, {
  model: "nova-2",
  smart_format: true,
  language: "en-US",
});


Transcription is then saved into MongoDB.

🧹 Notes

Uploaded files are stored in /uploads folder.

You can safely delete duplicate files manually; MongoDB entries will remain intact.

Always test with Postman before frontend integration.

Keep your .env file private (never push it to GitHub).