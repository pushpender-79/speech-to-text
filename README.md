ğŸ™ï¸ Speech-to-Text App (MERN Stack + Deepgram)

This project converts audio to text using the Deepgram Speech-to-Text API.
Itâ€™s built with the MERN stack â€” MongoDB, Express.js, React.js, and Node.js â€” and styled with Tailwind CSS.

ğŸš€ Tech Stack
Layer	Technology
ğŸ¨ Frontend	React + Vite + Tailwind CSS
âš™ï¸ Backend	Node.js + Express.js
ğŸ—„ï¸ Database	MongoDB (Mongoose)
ğŸ§  Speech-to-Text API	Deepgram
ğŸ§° Tools	Multer, dotenv, nodemon, Git & GitHub
ğŸ§  Project Overview

The app allows users to:

ğŸ¤ Record or upload audio

ğŸ”Š Convert it to text using Deepgram Speech-to-Text API

ğŸ’¾ Store audio file details & transcriptions in MongoDB

ğŸ§¾ Retrieve and display saved transcriptions (coming next)

ğŸ—“ï¸ Progress Overview
Day	Focus	Status
Day 1	Project setup (Vite + Tailwind + GitHub)	âœ… Done
Day 2	Backend setup with Express & Multer	âœ… Done
Day 3	MongoDB integration with Mongoose	âœ… Done
Day 4	Deepgram Speech-to-Text API integration	âœ… Done
Day 5	React UI for Upload & Recording	ğŸ”œ Next
âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone the Repository
git clone https://github.com/pushpender-79/speech-to-text
cd speech-to-text

2ï¸âƒ£ Frontend Setup
cd client
npm install
npm run dev


App runs at â¡ï¸ http://localhost:5173

3ï¸âƒ£ Backend Setup
cd ../server
npm install


Dependencies include:

express
cors
multer
dotenv
mongoose
@deepgram/sdk
nodemon (dev dependency)

4ï¸âƒ£ Environment Variables

Create a .env file inside the server folder:

PORT=5000
MONGO_URI=your_mongodb_connection_string
DEEPGRAM_API_KEY=your_deepgram_api_key

5ï¸âƒ£ Start the Backend Server
npm run dev


Server runs at â¡ï¸ http://localhost:5000

ğŸ§© API Endpoints
âœ… Test Route

GET http://localhost:5000/
Response:

"Backend is running ğŸš€"

ğŸ§ Upload & Transcribe Audio

POST http://localhost:5000/upload

Form Data:

Key	Type	Description
audio	File	Upload an audio file (.wav, .mp3, etc.)

Response Example:

{
  "message": "File uploaded and transcribed successfully",
  "file": {
    "originalname": "harvard.wav",
    "filename": "1760551563788.wav",
    "mimetype": "audio/wav",
    "path": "uploads/1760551563788.wav"
  },
  "transcription": "This is a sample transcription text generated by Deepgram."
}

ğŸ—„ï¸ MongoDB Schema (Day 3)
import mongoose from "mongoose";

const audioSchema = new mongoose.Schema({
  filename: { type: String, required: true },
  transcription: { type: String, default: "" },
  uploadedAt: { type: Date, default: Date.now },
});

export default mongoose.model("Audio", audioSchema);


Collection Name: audios

Field	Description
filename	File name stored on the server
transcription	Generated text after Deepgram transcription
uploadedAt	Timestamp of upload
ğŸ§  Deepgram API Integration (Day 4)

Using @deepgram/sdk v4:

import { createClient } from "@deepgram/sdk";
const deepgram = createClient(process.env.DEEPGRAM_API_KEY);

const { result } = await deepgram.listen.prerecorded.transcribeFile(audioBuffer, {
  model: "nova-2",
  smart_format: true,
  language: "en-US",
});


Transcription is then saved into MongoDB.

ğŸ§¹ Notes

Uploaded files are stored in /uploads folder.

You can safely delete duplicate files manually; MongoDB entries will remain intact.

Always test with Postman before frontend integration.

Keep your .env file private (never push it to GitHub).